{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "f = gzip.GzipFile(r\"../../Data/rBergomiTrainSet.txt.gz\", \"r\")\n",
    "dat=np.load(f)\n",
    "xx=dat[:,:4]\n",
    "yy=dat[:,4:]\n",
    "strikes=np.array([0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5 ])\n",
    "maturities=np.array([0.1,0.3,0.6,0.9,1.2,1.5,1.8,2.0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    xx, yy, test_size=0.15, random_state=42)\n",
    "\n",
    "def append_and_expand(a,x,y):\n",
    "    # use choose and where !\n",
    "    n = len(x)*len(y)\n",
    "    a_index = np.arange(len(a))%n\n",
    "    \n",
    "    \n",
    "    x_index = a_index//len(y)\n",
    "    y_index = a_index%len(y)\n",
    "    \n",
    "    x_added = np.choose(x_index,x.reshape(-1,1)).reshape(-1,1)\n",
    "    y_added = np.choose(y_index,y.reshape(-1,1)).reshape(-1,1)\n",
    "    \n",
    "    return np.hstack([a,x_added,y_added])\n",
    "\n",
    "y_train,y_test = y_train.reshape(-1,8,11),y_test.reshape(-1,8,11)\n",
    "x_train,x_test = np.repeat(x_train, 8*11,axis=0),np.repeat(x_test, 8*11,axis=0)\n",
    "\n",
    "x_train,x_test=append_and_expand(x_train,maturities,strikes),append_and_expand(x_test,maturities,strikes)\n",
    "y_train,y_test = y_train.reshape(-1).reshape(-1,1), y_test.reshape(-1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "scale_y=  StandardScaler()\n",
    "\n",
    "def ytransform(y_train,y_test):\n",
    "    return [scale_y.fit_transform(y_train),scale_y.transform(y_test)]\n",
    "\n",
    "def yinversetransform(y):\n",
    "    return scale_y.inverse_transform(y)\n",
    "\n",
    "# Upper and lower bounds used in the training set\n",
    "ub=np.array([0.16,4,-0.1,0.5,2.0,1.5])\n",
    "lb=np.array([0.01,0.3,-0.95,0.025,0.1,0.5])\n",
    "\n",
    "def myscale(x):\n",
    "    return (x - (ub+lb)*0.5)*2/(ub-lb)\n",
    "def myinverse(x):\n",
    "    return x*(ub-lb)*0.5+(ub+lb)*0.5\n",
    "\n",
    "x_train_transform = myscale(x_train)\n",
    "x_test_transform = myscale(x_test)\n",
    "[y_train_transform,y_test_transform] = ytransform(y_train,y_test)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"device is {device}\")\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x_train_transform).to(device=device),\n",
    "                                               torch.from_numpy(y_train_transform).to(device=device))\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(x_test_transform).to(device=device),\n",
    "                                              torch.from_numpy(y_test_transform).to(device=device))\n",
    "\n",
    "\n",
    "train_data = (torch.from_numpy(x_train_transform).to(device=device),torch.from_numpy(y_train_transform).to(device=device))\n",
    "test_data = (torch.from_numpy(x_test_transform).to(device=device),torch.from_numpy(y_test_transform).to(device=device))\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset,batch_size =64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')  # Add the parent directory to the Python path\n",
    "\n",
    "from torch_NN.nn import KAN\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# hyperparas = {'input_dim':6,'hidden_dim':32,'hidden_nums':2,'output_dim':1,'block_layer_nums':2}\n",
    "\n",
    "layers_list_for_KAN = [x_train.shape[-1],32,1]\n",
    "\n",
    "model = KAN(layers_hidden=layers_list_for_KAN).to(device=device,dtype=torch.float64)\n",
    "loss_MSE = nn.MSELoss()\n",
    "optim_Adam = torch.optim.Adam(model.parameters(),lr= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Epoch: 0----------------------------------\n",
      "Batch: 0,train loss is: 0.9670504989845168\n",
      "test loss is 0.9583719919672382\n",
      "Batch: 100,train loss is: 0.4991621510608279\n",
      "test loss is 0.48389917378312747\n",
      "Batch: 200,train loss is: 0.16771359738944408\n",
      "test loss is 0.22838700769512124\n",
      "Batch: 300,train loss is: 0.11429038570622288\n",
      "test loss is 0.12450344248355102\n",
      "Batch: 400,train loss is: 0.056407967085330385\n",
      "test loss is 0.06266983121771388\n",
      "Batch: 500,train loss is: 0.053542319014817444\n",
      "test loss is 0.04009576831836549\n",
      "Batch: 600,train loss is: 0.017643828720675873\n",
      "test loss is 0.0266673745010908\n",
      "Batch: 700,train loss is: 0.014546192338296569\n",
      "test loss is 0.0203611317370701\n",
      "Batch: 800,train loss is: 0.008922687775220386\n",
      "test loss is 0.016092279444485533\n",
      "Batch: 900,train loss is: 0.026558699619330224\n",
      "test loss is 0.013315934886236915\n",
      "Batch: 1000,train loss is: 0.018278349842863747\n",
      "test loss is 0.010973477226492398\n",
      "Batch: 1100,train loss is: 0.00580273619572746\n",
      "test loss is 0.009446169300522621\n",
      "Batch: 1200,train loss is: 0.005328563906901033\n",
      "test loss is 0.00847674351670199\n",
      "Batch: 1300,train loss is: 0.007223936378688658\n",
      "test loss is 0.00748907162946582\n",
      "Batch: 1400,train loss is: 0.004079316020233076\n",
      "test loss is 0.007194818876632465\n",
      "Batch: 1500,train loss is: 0.006802592018399212\n",
      "test loss is 0.006594646958357998\n",
      "Batch: 1600,train loss is: 0.0058820993650757795\n",
      "test loss is 0.005705989225621725\n",
      "Batch: 1700,train loss is: 0.0029982179118807463\n",
      "test loss is 0.005288844437479869\n",
      "Batch: 1800,train loss is: 0.0034252345847554273\n",
      "test loss is 0.004939142152326117\n",
      "Batch: 1900,train loss is: 0.0038830186296001943\n",
      "test loss is 0.004555033759779564\n",
      "Batch: 2000,train loss is: 0.0029845852299065882\n",
      "test loss is 0.004152681227775987\n",
      "Batch: 2100,train loss is: 0.0023306001654795497\n",
      "test loss is 0.004024165757922858\n",
      "Batch: 2200,train loss is: 0.002174215770380408\n",
      "test loss is 0.0036545516749803683\n",
      "Batch: 2300,train loss is: 0.005921230118129714\n",
      "test loss is 0.0036103094786538318\n",
      "Batch: 2400,train loss is: 0.0032411429115705853\n",
      "test loss is 0.003249789881213528\n",
      "Batch: 2500,train loss is: 0.0025629066091193723\n",
      "test loss is 0.003233808837086609\n",
      "Batch: 2600,train loss is: 0.003054923074736246\n",
      "test loss is 0.003079667333735189\n",
      "Batch: 2700,train loss is: 0.003026760808867595\n",
      "test loss is 0.00293751621407197\n",
      "Batch: 2800,train loss is: 0.0029946624098419646\n",
      "test loss is 0.002781534832426619\n",
      "Batch: 2900,train loss is: 0.0038820175939940065\n",
      "test loss is 0.002690197641389002\n",
      "Batch: 3000,train loss is: 0.0028026395930209344\n",
      "test loss is 0.0026386166897088377\n",
      "Batch: 3100,train loss is: 0.0023070805813220066\n",
      "test loss is 0.002536936436323196\n",
      "Batch: 3200,train loss is: 0.002347163911358384\n",
      "test loss is 0.002436622879986253\n",
      "Batch: 3300,train loss is: 0.0019396043990351525\n",
      "test loss is 0.0023074124294660556\n",
      "Batch: 3400,train loss is: 0.002175641620363957\n",
      "test loss is 0.002317477654993747\n",
      "Batch: 3500,train loss is: 0.0013964638088582364\n",
      "test loss is 0.002163933091014985\n",
      "Batch: 3600,train loss is: 0.0011095975990753361\n",
      "test loss is 0.0021497572651754645\n",
      "Batch: 3700,train loss is: 0.001265094882368531\n",
      "test loss is 0.002057281358104395\n",
      "Batch: 3800,train loss is: 0.0010336956258753843\n",
      "test loss is 0.00208964999090738\n",
      "Batch: 3900,train loss is: 0.001739612269592266\n",
      "test loss is 0.0020679845518736173\n",
      "Batch: 4000,train loss is: 0.0015825191361367617\n",
      "test loss is 0.001891184096055593\n",
      "Batch: 4100,train loss is: 0.001836837353268747\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_NN\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_model\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_MSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptim_Adam\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/biyesheji/NN-StochVol-Calibrations/pointwise/RoughBergomi/../../torch_NN/train.py:38\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(loss_function, optimizer, model, loader, train_data, test_data, epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     36\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m----------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m   train_loss_list\u001b[38;5;241m.\u001b[39mappend(loss[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     40\u001b[0m   test_loss_list\u001b[38;5;241m.\u001b[39mappend(loss[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/biyesheji/NN-StochVol-Calibrations/pointwise/RoughBergomi/../../torch_NN/train.py:23\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(loss_function, optimizer, model, loader, train_data, test_data)\u001b[0m\n\u001b[1;32m     21\u001b[0m       test_outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(test_data[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     22\u001b[0m       test_loss \u001b[38;5;241m=\u001b[39m loss_function(test_outputs,test_data[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest loss is \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtest_loss\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     26\u001b[0m   train_loss \u001b[38;5;241m=\u001b[39m loss_function(model(train_data[\u001b[38;5;241m0\u001b[39m]),train_data[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/initial/lib/python3.12/site-packages/torch/_tensor.py:965\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, format_spec)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch_NN.train import train_model\n",
    "\n",
    "train_model(loss_MSE,optim_Adam,model,data_loader,train_data,test_data,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "initial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
